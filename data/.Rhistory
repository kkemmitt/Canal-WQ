library(car) # if anybody has problems with this, try install dependencies manually, lme4 is the problematic one
library(ggplot2) # this will  need to be installed
library(pwr) # this will  need to be installed
nn1=6#sample size of sample1
nn2=12#sample size of sample 2
class(nn1) # nn1 is just a number
sample1=c( 8.736339,55.463842,62.358608,47.560199,47.525478,32.294160) #we create (concatenate) elements into a vector
length(sample1) # we could have specified nn1 as the length of the vector
sample2=c(18.08182,45.05992,33.45347,22.45844,33.16731,22.19066,17.68734,14.81729,35.17519,35.23651,45.98866,48.19830)
summary(sample1) #summary stats: different means!
summary(sample2)
yy=c(sample1,sample2) # stacking y values into a vector
yy
cats=c(rep('sample1',nn1),rep('sample2',nn2)) # stacking the categorical or classifying variables
cats
xx=factor(cats) # making cats a factor for a t-test
class(xx) # yes, we have created a factor
dataStack=data.frame(cbind(xx,yy))# c olumn stacked data #xx is factors and yy is data corresponding
class(dataStack) # data frames are "lists of vectors", can contain characters and numbers and are very useful/flexible for storing data tables
View(dataStack)
cats
xx
class(xx)
sample1=c(sample1,rep(NA,(max(nn1,nn2))-nn1)) # making two equal length vectors to avoid sparse matrix, adding NA's so that sample 1 and 2 have same length
sample1
sample2=c(sample2,rep(NA,(max(nn1,nn2))-nn2)) # making two equal length vectors to avoid sparse matrix
sample2
data=cbind(sample1,sample2) # making a matrix with groups by column
data # this is what we just created
boxplot(data) # visualize data
resids=(scale(data)[,1:2]) # normalized residuals
qqPlot(resids) # normality assessment
Ftest=max(var(sample1,na.rm = TRUE),var(sample2,na.rm = TRUE))/min(var(sample1,na.rm = TRUE),var(sample2,na.rm = TRUE))
sigFtest=2*pf(Ftest,max(nn1,nn2),min(nn1,nn2),lower.tail = FALSE) # pf = distribution function, need to specify F, multiplying by 2 to get two tailed test degrees of freedom 1 and 2 #want p>.05
sigFtest # are we good to proceed?
signal=(mean(sample1,na.rm = TRUE)-mean(sample2,na.rm = TRUE)) # numerator of the t statistic (mean difference)
sp2=sum((sample1-mean(sample1,na.rm = TRUE))^2,(sample2-mean(sample2,na.rm = TRUE))^2,na.rm = TRUE)/(nn1+nn2-2) # for the denominator we first need to compute the pooled variance
noise=sqrt((sp2/nn1)+(sp2/nn2)) # denominator of the t statistic
tStat=signal/noise
tStat
sigT=2*pt(tStat,(nn1+nn2-2),lower.tail=FALSE)
sigT # reject or accept H0?
attach(dataStack) # need to set up dataStack in WG
out1=t.test(yy~xx,alternative="two.sided",mu=0,paired=FALSE,var.equal=TRUE) # lots of options here, same result!
out1
?t.test
cohen.d=signal/sqrt(sp2) # Cohen's d is defined as the difference between two means divided by a standard deviation for the data
cohen.d
Power.U=pwr.t2n.test(n1=nn1,n2=nn2,d=cohen.d,power=NULL,sig.level=0.05)# two saample t test function for assessing power
calcPower=Power.U$power
calcPower
?rnorm
s1<-rnorm(100, mean=0, sd=2000)
s2<-rnorm(100, mean=100, sd=4000)
n=100 # number of points
a=100
b1=3 #slopes
b2=0.001
b3=0.1
MSE1=0.5
MSE2=3*MSE1
MSE3=3*MSE2
x1 <- rnorm(n,mean=30,sd=9)#using mean not equal zero here to center distribution away from zero
x2 <- x1^2#ditto
x3<- x1^3#this one has log normal
X<- cbind(x1, x2, x3)#matrix of xs
X
boxplot(X)
y <- a + b1*X[,1] + b2*X[,2] + b3*X[,3]+rnorm(n, 0, MSE2)
df <- data.frame(response=y, driver1=X[,1],driver2=X[,2],driver3=X[,3])
write.csv(df,file="mlRegData1new.csv")
data=read.csv("mlRegData1new.csv")
attach(data)
op <- par(mfrow = c(3, 1), mar=c(3,3,3,3))
plot(driver1,response,main="X1 vs Y")
plot(driver2,response,main="X2 vs Y")
plot(driver3,response,main="X3 vs Y")
par(op)
XX=cbind(driver1,driver2,driver3)
pairs(data)
pairs(XX)
outA<-lm(response~driver1+driver2+driver3)
op <- par(mfrow = c(2, 2), # 2 x 2 pictures on one plot
pty = "m")       # square plotting region,
# independent of device size
plot(outA)
par(op)
library(car)
qqPlot(scale(outA$residuals)[,1])#standard QQ for normality
outlierTest(outA) # Bonferonni p-value for most extreme obs
leveragePlots(outA) # leverage plots
cutoff <- 4/((n-length(outA$coefficients)-2))
plot(outA, which=4, cook.levels=cutoff)#plots cooks D, dont want these to be greater than 4/n
outCor<-cor(X)#correlation coeficients, look for R > 0.4 (conservative) or R>0.6 (acceptable)
outCor
tCor<-outCor/sqrt((1-outCor^2)/(n-2))#t-values for R
pCor<-1-pt(tCor,n-2)#significance testing for Rs, remember balance between sample size and significance
pCor
vif(outA) # variance inflation factors
vif(outA)>5 #(want these to be false, less than 5)
sqrt(vif(outA)) > 2 # want these to be false (less than ~2)
data=read.csv("mlRegData1new.csv")
attach(data)
y=response
x1=driver1
x2=driver2
x3=driver3
summary(outA)#driver2 isn't important
out1=lm(y~x1+x2+x3)#full model (5 coef)
out2=lm(y~x1+x2)#4 coef model
out3=lm(y~x1+x3)#4 coef model
out4=lm(y~x2+x3)#4 coef model
out5=lm(y~x1)#3 coef model
out6=lm(y~x2)#3 coef model
out7=lm(y~x3)#3 coef model
aics=c(AIC(out1),AIC(out2),AIC(out3),AIC(out4),AIC(out5),AIC(out6),AIC(out7))
aics
delAICs=aics-min(aics)
delAICs
likes=exp(-0.5*delAICs)
likes
ws=round(likes/sum(likes),3)
ws
matWS=cbind(ws,ws,ws,ws)
coeff1=summary(out1)$coefficients[,1]
coeff2=c(summary(out2)$coefficients[,1],NA)
coeff3=c(summary(out3)$coefficients[1:2,1],NA,summary(out3)$coefficients[3,1])
coeff4=c(summary(out4)$coefficients[1,1],NA,summary(out4)$coefficients[2:3,1])
coeff5=c(summary(out5)$coefficients[,1],NA,NA)
coeff6=c(summary(out6)$coefficients[1,1],NA,summary(out6)$coefficients[1,2],NA)
coeff7=c(summary(out7)$coefficients[1,1],NA,NA,summary(out7)$coefficients[1,2])
coeffs=rbind(coeff1,coeff2,coeff3,coeff4,coeff5,coeff6,coeff7)
matWS=cbind(ws,ws,ws,ws)
wcoeffs=colSums(ws*coeffs,na.rm = TRUE)
wcoeffs #include terms that are important
ws
step=step(lm(y~x1+x2+x3), direction="backward", trace=1)
coeffs=rbind(coeff1,coeff2,coeff3,coeff4,coeff5,coeff6,coeff7)
matWS=cbind(ws,ws,ws,ws)
binaryCoef=coeffs/coeffs
vWeights=coljSums(ws*binaryCoef,na.rm=TRUE)
vWeights=colSums(ws*binaryCoef,na.rm=TRUE)
vWeights
wcoeffs=colSums(ws*coeffs,na.rm = TRUE)
wcoeffs=colSums(ws*coeffs
)
ws*coeffs
wcoeffs
matWS=cbind(ws,ws,ws,ws)
aics=c(AIC(out1),AIC(out2),AIC(out3),AIC(out4),AIC(out5),AIC(out6),AIC(out7))
aics
delAICs=aics-min(aics)
delAICs
likes=exp(-0.5*delAICs)
likes
ws=round(likes/sum(likes),3)
ws
matWS=cbind(ws,ws,ws,ws)
coeffs=rbind(coeff1,coeff2,coeff3,coeff4,coeff5,coeff6,coeff7)
coeffs=rbind(coeff4,coeff6,coeff7)
matWS=cbind(ws,ws,ws,ws)
binaryCoef=coeffs/coeffs
vWeights=colSums(ws*binaryCoef,na.rm=TRUE)
vWeights
wcoeffs=colSums(ws*coeffs,na.rm = TRUE)
wcoeffs
a=150
b1=17.8
b2=-0.5
b3=0.08
x=1:1:35
N=length(x)
sigmaa=25
x
N=length(x)
noise=rnorm(N,mean=0,sd=sigmaa)
noise
yLin=a+b1/4*x
yLinC=yLin+noise
plot(yLin)
yQuad=a+b1*x+b2*x^2
yQuadC=yQuad+noise
yQuadC
yCube=1.1*(a*3.5+b1*x+b2*(6)*x^2+b3*x^3)
yCubeC=yCube+noise
op=par(mfrow=(c(3,1)),cex.axis=1.5,cex.lab=1.5)
plot(yLin,type="l",col="black",lwd=2,xlab="",ylim=c(100,500))
points(x,yLinC,pch=16,col="red")
plot(yQuad,col="black",type="l",lwd=2,xlab="",ylim=c(100,500))
plot(yCube,col="black",type="l",lwd=2,xlab="Driver",ylim=c(0,1000))
points(x,yCubeC,pch=16,col="red")
points(x,yQuadC,pch=16,col="red")
par(op)
a=150
b1=17.8
b2=-0.5
b3=0.08
x=1:1:35
N=length(x)
sigmaa=25
#sigmaa=200
noise=rnorm(N,mean=0,sd=sigmaa)
#linear
yLin=a+b1/4*x
yLinC=yLin+noise
plot(yLin)
#Quadratic
yQuad=a+b1*x+b2*x^2
yQuadC=yQuad+noise
#Cubic
yCube=1.1*(a*3.5+b1*x+b2*(6)*x^2+b3*x^3)
yCubeC=yCube+noise
op=par(mfrow=(c(3,1)),cex.axis=1.5,cex.lab=1.5)
plot(yLin,type="l",col="black",lwd=2,xlab="",ylim=c(100,500))
points(x,yLinC,pch=16,col="red")
plot(yQuad,col="black",type="l",lwd=2,xlab="",ylim=c(100,500))
points(x,yQuadC,pch=16,col="red")
plot(yCube,col="black",type="l",lwd=2,xlab="Driver",ylim=c(0,1000))
points(x,yCubeC,pch=16,col="red")
par(op)
o1=lm(yCubeC~ x)#linear
o2=lm(yCubeC~ x + I(x^2))#quadratic
o3=lm(yCubeC~ x + I(x^2) + I(x^3))#cubic
aicLin=AIC(o1)
aicQuad=AIC(o2)
aicCub=AIC(o3)
#Now lets see which of the three best fits the quad dataset
#note that this is one realization, so might end up being non-quadratic by chance
o4=lm(yQuadC~ x)#linear
o5=lm(yQuadC~ x + I(x^2))#quadratic
o6=lm(yQuadC~ x + I(x^2) + I(x^3))#cubic
aicLin2=AIC(o4)
aicQuad2=AIC(o5)
aicCub2=AIC(o6)
aics=rbind(aicLin2, aicQuad2, aicCub2)
delAICs=aics-min(aics)
likes=exp(-0.5*delAICs)
delAICs
wss=likes/sum(likes)
wss
varWss=rbind(sum(wss), sum(wss[2:3]), sum(wss[3]))
summary(o4)$coefficients
summary(o6)$coefficients
library(streamMetabolizer)
library(httr)
devtools::install_github("USGS-R/streamMetabolizer@develop")
library(httr)
library(jsonlite)
library(tidyr)
library(dplyr)
library(devtools)
suppressMessages(source_gist("2626629e50d191394285a61a0c678779"))
fitdata <- sp_metab(sitecode = "AZ_OC",
startdate = "2016-11-14",
enddate = "2016-12-09",
type = "mle",
token = NULL)
setwd("C:/Users/Katie Kemmitt/OneDrive/Research/Drinking-Water-Canal-Data")
read.csv("617_nutrients_f188850a9e51c192bbe89b680f40c7cc934463af.csv")
data<-read.csv("617_nutrients_f188850a9e51c192bbe89b680f40c7cc934463af.csv")
View(data)
plot(data$Tot_N ~ data$Date)
library("ggplot2", lib.loc="~/R/win-library/3.3")
attach(data)
ggplot(Tot_N, data=data, geom=boxplot, color=Site_Acronym)
ggplot(aes(Tot_N, data=data), geom=boxplot, color=Site_Acronym)
ggplot(data, aes(x=Date, y=Tot_N, color=Site_Acronym))
ggplot(data, aes(x=Date, y=Tot_N, color=Site_Acronym))+ geom_point()
ggplot(data, aes(x=Date, y=Tot_N))+ geom_point()
ggplot(data, aes(x=Tot_P, y=Tot_N))+ geom_point()
setwd("C:/Users/Katie Kemmitt/OneDrive/Research/Drinking-Water-Canal-Data")
data1<-read.csv("617_quarterlyLakeSampling.csv")
View(data1)
setwd("C:/Users/Katie Kemmitt/OneDrive/Research/Drinking-Water-Canal-Data/data")
install.packages("streamMetabolizer", dependencies=TRUE,
repos=c("https://owi.usgs.gov/R","https://cran.rstudio.com"))
update.packages(oldPkgs=c("streamMetabolizer","unitted"),
dependencies=TRUE, repos=c("https://owi.usgs.gov/R", "https://cran.rstudio.com"))
library(dplyr)
library(tidyr)
library(ggplot2)
library(streamMetabolizer)
library("streamMetabolizer", lib.loc="~/R/win-library/3.3")
remove.packages("streamMetabolizer", lib="~/R/win-library/3.3")
library(streamMetabolizer)
install.packages("streamMetabolizer", dependencies=TRUE,
repos=c("https://owi.usgs.gov/R","https://cran.rstudio.com"))
update.packages(oldPkgs=c("streamMetabolizer","unitted"),
dependencies=TRUE, repos=c("https://owi.usgs.gov/R", "https://cran.rstudio.com"))
library(streamMetabolizer)
remove.packages("streamMetabolizer", lib="~/R/win-library/3.3")
install.packages("streamMetabolizer")
install.packages("streamMetabolizer", dependencies=TRUE,
repos=c("https://owi.usgs.gov/R","https://cran.rstudio.com"))
library("streamMetabolizer", lib.loc="~/R/win-library/3.3")
library(streamMetabolizer)
which
devtools::install_github("USGS-R/streamMetabolizer@develop")
library(streamMetabolizer)
